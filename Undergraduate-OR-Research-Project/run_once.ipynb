{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the modules\n",
    "from gurobipy import *\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Once(clean the original data and write into a new csv file) <a name=\"call_once\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  2091  of patients for  fbmh .\n",
      "There are  3838  of patients for  ibhs .\n"
     ]
    }
   ],
   "source": [
    "def get_patient_improvement(data, drop_list):\n",
    "    data = data.drop(drop_list, axis = 1)\n",
    "    pat_num = data.shape[0]//2\n",
    "    numneed = data.shape[1]\n",
    "    improvements = {}\n",
    "    for r in range(pat_num):        \n",
    "        improvements[r] = [0 for i in range(numneed)]\n",
    "        for c in range(numneed):\n",
    "            improvements[r][c] =  data.iloc[2*r,c] - data.iloc[2*r+1,c] \n",
    "    improvements = pd.DataFrame.from_dict(improvements,orient='index')\n",
    "    return improvements\n",
    "\n",
    "def covert_to_int(string):\n",
    "    [_, date, year] = string.split(\",\")\n",
    "    [_,month,day] = date.split(\" \")\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    if int(day)<10:\n",
    "        day = \"0\" + day \n",
    "    for i in range(len(months)):\n",
    "        if months[i] == month:\n",
    "            if i >= 9:\n",
    "                return year[1:] + \"-\" + str(i+1) + \"-\" + day\n",
    "            else:\n",
    "                return year[1:] + \"-\" + \"0\"+str(i+1) + \"-\"+day\n",
    "            \n",
    "def clean_data(df,treatment):\n",
    "    #keep columns that we need\n",
    "    index_to_keep = None\n",
    "    if treatment == \"ibhs\":\n",
    "        index_to_keep = [df.columns[2]] + list(df.columns[4:98]) + [df.columns[206]] + [df.columns[100]]\n",
    "    else:\n",
    "        index_to_keep = [df.columns[2]] + list(df.columns[4:98]) + [df.columns[198]] + [df.columns[100]]\n",
    "    df = df[index_to_keep]\n",
    "    \n",
    "    #remove clients appear less than 2\n",
    "    df = df.sort_values(by = 'client_id')\n",
    "    if treatment == \"ibhs\":\n",
    "        df = df[df['timeline_ibhs'] != 'CONTINUED']\n",
    "    else:\n",
    "        df = df[df['timeline_fbmh'] != 'CONTINUED']\n",
    "    df = df[df.groupby('client_id')['client_id'].transform('count').ge(2)]\n",
    "    \n",
    "    # change the english strings to int strings\n",
    "    rows = df.shape[0]\n",
    "    for r in range(rows):\n",
    "        df.iloc[r,96] = covert_to_int(df.iloc[r,96])\n",
    "        if df.iloc[r,95] == 'INITIAL': \n",
    "            df.iloc[r,95] = 'A-INITIAL' #have initial before discharged for sorting later\n",
    "            \n",
    "    # sort data by client id, timeline(initial vs. discharge), and date of evaluation\n",
    "    if treatment == \"ibhs\":\n",
    "        df = df.sort_values([\"client_id\", \"timeline_ibhs\", \"evaluated_at\"], ascending=True)\n",
    "        df.rename(columns = {'timeline_ibhs': 'timeline'}, inplace = True)\n",
    "    else:\n",
    "        df = df.sort_values([\"client_id\", \"timeline_fbmh\", \"evaluated_at\"], ascending=True)\n",
    "        df.rename(columns = {'timeline_fbmh': 'timeline'}, inplace = True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # keep the earliest initial and latest discharged for each client, and remove any clients have both\n",
    "    drop_rows = []\n",
    "    prev_client = None\n",
    "    cur_client = None\n",
    "    next_client = None\n",
    "    for r in range(df.shape[0]):\n",
    "        cur_client = df.iloc[r, 0]\n",
    "        if r < df.shape[0]-1:\n",
    "            next_client = df.iloc[r+1, 0]\n",
    "        else:\n",
    "            next_client = None\n",
    "\n",
    "        if df.iloc[r, 95] == 'A-INITIAL' and prev_client == cur_client and prev_client != None:\n",
    "            drop_rows.append(r)\n",
    "        elif df.iloc[r, 95] == 'DISCHARGED':\n",
    "            if next_client == cur_client:\n",
    "                drop_rows.append(r)\n",
    "        prev_client = cur_client\n",
    "\n",
    "\n",
    "    rows = df.index[drop_rows]\n",
    "    df.drop(rows, inplace=True) \n",
    "    \n",
    "    # remove clients with less than 2 rows\n",
    "    df = df[df.groupby('client_id')['client_id'].transform('count').ge(2)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # df_ibhs.client_id.value_counts()\n",
    "    \n",
    "    \n",
    "    #find list of patients\n",
    "    clients = df['client_id'].unique().tolist()\n",
    "    print(\"There are \",df.shape[0]//2,\" of patients for \", treatment, \".\")\n",
    "    \n",
    "    return df, clients\n",
    "\n",
    "def clean_all():\n",
    "    ibhs = pd.read_excel('history_dataset/cans_ibhs_fbmh.xlsx',sheet_name=0)\n",
    "    fbmh = pd.read_excel('history_dataset/cans_ibhs_fbmh.xlsx',sheet_name=1)\n",
    "    fbmh_df,fbmh_patients = clean_data(fbmh,'fbmh')\n",
    "    ibhs_df,ibhs_patients = clean_data(ibhs,'ibhs')\n",
    "    return ((fbmh_df,fbmh_patients),(ibhs_df,ibhs_patients))\n",
    "\n",
    "\n",
    "(fbmh_clean_df,fbmh_patients),(ibhs_clean_df,ibhs_patients) = clean_all()\n",
    "\n",
    "#find an improvement table for every pateint(row) and need(col)\n",
    "droplist = ['client_id','timeline', 'evaluated_at']\n",
    "ibhs_imp = get_patient_improvement(ibhs_clean_df, droplist)\n",
    "fbmhs_imp = get_patient_improvement(fbmh_clean_df, droplist)\n",
    "\n",
    "#remove rows with all 0's\n",
    "# df.loc[~(df==0).all(axis=1)]\n",
    "ibhs_all_imp = ibhs_imp.loc[~(ibhs_imp==0).all(axis=1)].reset_index(drop=True)\n",
    "fbmhs_all_imp = fbmhs_imp.loc[~(fbmhs_imp==0).all(axis=1)].reset_index(drop=True)\n",
    "\n",
    "#write the improv_table to local\n",
    "ibhs_all_imp.to_csv('improve_table_real_set/ibhs_all_improv_table.csv',index=False)\n",
    "fbmhs_all_imp.to_csv('improve_table_real_set/fbmhs_all_improv_table.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep top-level items <a name=\"keep_top_level_items\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ibhs_df = pd.read_csv('ibhs_all_improv_table.csv')\n",
    "old_fbmh_df = pd.read_csv('fbmhs_all_improv_table.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_column_names = ['pp01', 'pp02', 'pp03', 'pp04', \n",
    "                    'pp05', 'pp06', 'pp07', 'pp08', \n",
    "                    'pp09', 'pp10', 'pp11', 'pp12', \n",
    "                    'pp13', 'pp14', 'pp15', 'pp16', \n",
    "                    'pp17', 'pp18', 'pp19', 'rb01', \n",
    "                    'rb02', 'rb03', 'rb04', 'rb05', \n",
    "                    'rb06', 'rb07', 'rb08', 'rb09', \n",
    "                    'rb10', 'rb11', 'rb12', 'rb13', \n",
    "                    'rb14', 'rb15', 'rb16', 'rb17', \n",
    "                    'rb18', 'rb19', 'rb20', 'rb21', \n",
    "                    'rb22', 'rb23', 'rb24', 'rb25', \n",
    "                    'rb26', 'rb27', 'rb28', 'fu01', \n",
    "                    'fu02', 'fu03', 'fu04', 'fu05', \n",
    "                    'fu06', 'fu07', 'fu08', 'fu09', \n",
    "                    'fu10', 'fu11', 'fu12', 'fu13', \n",
    "                    'fu14', 'fu15', 'fu16', 'fu17', \n",
    "                    'fu18', 'fu19', 'fu20', 'fu21', \n",
    "                    'fu22', 'fu23', 'fu24', 'fu25', \n",
    "                    'fu26', 'fu27', 'cs01', 'cn01', \n",
    "                    'cn02', 'cn03', 'cn04', 'cn05', \n",
    "                    'cn06', 'cn07', 'st01', 'st02', \n",
    "                    'st03', 'st04', 'st05', 'st06', \n",
    "                    'st07', 'st08', 'st09', 'st10', 'st11', 'st12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 53 top-level items\n",
    "# change index into column names\n",
    "old_ibhs_df.columns = all_column_names\n",
    "old_fbmh_df.columns = all_column_names\n",
    "# keep the needed columns \n",
    "column_names_df = pd.read_csv('CANS Items for MILP Profile - Sheet1.csv')\n",
    "column_names = list(column_names_df['Standradized Field'])\n",
    "ibhs_df = old_ibhs_df[column_names]\n",
    "fbmh_df = old_fbmh_df[column_names]\n",
    "#change index back to integer \n",
    "index = [i for i in range(53)]\n",
    "ibhs_df.columns = index\n",
    "fbmh_df.columns = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the top_level_improv_table to local\n",
    "ibhs_df.to_csv('improve_table_real_set/ibhs_all_improv_table_top_level.csv',index=False)\n",
    "fbmh_df.to_csv('improve_table_real_set/fbmhs_all_improv_table_top_level.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
